%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{CONCLUSION}\label{ch:conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this thesis, after a brief introduction about LPWAN technologies, LoRa modulation basics and spreading factor assignment issue is discussed. An open source discrete event simulator is presented, which is developed from scratch to study network performance of LoRaWAN and evaluate various spreading factor assignment schemes. Moreover, it is shown how same spreading factor collisions can be avoided, hence, machine learning based solutions called smart DTC scheme and smart SVM scheme are proposed. Simulation results for the lowest spreading factor assignment scheme and the proposed schemes are presented. Simulation results show that, the proposed smart schemes can increase network performance for LoRaWAN networks, especially, when the nodes are deployed close to gateways.

LPWAN technologies sacrifice data rate and latency to provide low power and long range communication. Focus of this thesis is on LoRa which is one of the most popular LPWAN technologies. In LoRa modulation, the signal frequency scans the band from end to end within a particular channel. The speed of the scan is called the spreading factor. As the spreading factor increases, the data rate decreases and the power consumption increases, however the communication range increases. LoRa transmissions with different spreading factors within the same channel can communicate without causing interference to each other. Therefore, spreading factor selection of the end nodes significantly affects the number of collisions thus the network performance. It is difficult for end nodes to select the best spreading factor for them, since the end nodes are not aware of the transmissions around them. End nodes select the lowest spreading factor they can to communicate with the gateways to keep the power consumption low, to keep the communication duration short and reduce the likelihood of collisions. However, when other end nodes around them begin to transmit with the same spreading factor, the probability of collisions increases. Same spreading factor transmissions can significantly reduce network performance in densely deployed networks. Assignment of a higher spreading factor may increase the successful packet delivery ratio, even if the end nodes are close to the gateway.

In this study, the effect of spreading factor assignment on network performance is investigated in detail. The factors that increase the number of collisions is evaluated and measures that can be taken to reduce the number of collisions is described. A novel method which utilizes machine learning techniques is proposed to select the most efficient spreading factor. Support Vector Machine and Decision Tree Classifier machine learning methods are used for this new method called smart spreading factor assignment. In this method, gateways first monitor the location of each node, spreading factor of each transmission and result of each transmission. Then, gateways train a transmission prediction model with accumulated data by using SVM or DTC machine learning methods. With this model, the most efficient speeding factor is calculated for subsequent transmissions of the nodes. For each end node, transmission result prediction is calculated one by one from lowest speeding factor to highest spreading factor. The spreading factor of the first transmission projected as successful is selected for the end node. Gateways notify the new spreading factors to the end nodes. The end nodes will begin to use the new spreading factors for their subsequent transmissions. The simulation results show that the smart spreading factor assignment method yields better network packet delivery ratio and total transmission energy consumption than random spreading factor assignment method and lowest spreading factor assignment method. DTC machine learning method gives better packet delivery ratio results than SVM machine learning method. These two smart spreading factor assignment methods provide promising network performance improvements, especially for dense LoRaWAN networks.

As for future work, transmit power optimization can be included to the proposed smart schemes. In this thesis, it is assumed that nodes always use maximum transmit power for uplink transmission, however nodes close to gateways can decrease transmit power to save energy. This will make transmissions more vulnerable to interference thus requires extra care. Also other proposed SF assignment schemes described in Chapter \ref{ch:related_works} can be integrated to simulation tool for comparing other proposed SF assignment schemes. In this thesis, it is also assumed that only LoRaWAN Class A end nodes are present, however Class B and Class C end node behavior can be integrated to check how extra downlink communication effects smart SF schemes. Moreover, other machine learning methods can be investigated for spreading factor assignment enhancement. Reinforcement learning could be a good candidate. Also, other transmission parameters such as node id and transmission time can be included to the proposed scheme in order to improve prediction performance.
